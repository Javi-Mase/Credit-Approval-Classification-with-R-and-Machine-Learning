# Aplicar configuración
ejecutar_configuracion_svm(preprocesamientos, "credit.Datos.knn.Train", "credit.Datos.knn.Test")
# Definir variables de entrada y salida
credit.Var.Salida.Usada <- "V16"
credit.Vars.Entrada.Usadas <- setdiff(names(credit.Datos.knn.Train), credit.Var.Salida.Usada)
# Entrenar el modelo
modelo_entrenado <- train(
x = credit.Datos.knn.Train[, credit.Vars.Entrada.Usadas],
y = credit.Datos.knn.Train[[credit.Var.Salida.Usada]],
method = "knn",
trControl = credit.trainCtrl,
tuneGrid = data.frame(
k = 13
),
metric = "Accuracy"
)
# Guardar modelo
modelos_entrenados_knn[[nombre_config]] <- modelo_entrenado
# Mostrar información del modelo actual
print(paste("Modelo entrenado para la configuración:", nombre_config))
}
# Comparar modelos usando resamples()
resultados_resampling <- resamples(modelos_entrenados_knn)
# Mostrar estadísticas resumidas
summary(resultados_resampling)
# Graficar resultados
bwplot(resultados_resampling, metric = "Accuracy")
dotplot(resultados_resampling, metric = "Accuracy")
# Prueba estadística de diferencias
diferencias_modelos <- diff(resultados_resampling)
summary(diferencias_modelos)
credit.Datos.knn.Train <- credit.Datos.Train
credit.Datos.knn.Test <- credit.Datos.Test
norm_range("credit.Datos.knn.Train", "credit.Datos.knn.Test")
dummy("credit.Datos.knn.Train", "credit.Datos.knn.Test")
eliminar_varianza_cero_svm("credit.Datos.knn.Train", "credit.Datos.knn.Test")
# Configurar el modelo KNN
set.seed(1234)
# Entrenamiento del modelo k-NN
credit.modelo.knn <- train(
V16 ~ .,
data = credit.Datos.knn.Train,
method = "knn",  # Especificamos k-NN
trControl = credit.trainCtrl,
tuneLength = 20)
#Mostrar porcentaje final
# Realizar predicciones en el conjunto de prueba
predicciones_test <- predict(credit.modelo.knn, credit.Datos.knn.Test)
# Generar la matriz de confusión
matriz_confusion <- confusionMatrix(predicciones_test, credit.Datos.knn.Test[[credit.Var.Salida.Usada]])
# Extraer el porcentaje de acierto
porcentaje_acierto <- matriz_confusion$overall["Accuracy"] * 100
# Mostrar el porcentaje de acierto
print(paste("Porcentaje de acierto:", round(porcentaje_acierto, 2), "%"))
modelLookup(("knn"))
credit.modelo.knn$bestTune
set.seed(2)
credit.modelo.final.knn <- train(
V16 ~ .,
data = credit.Datos.knn.Train,
method = "knn",
trControl =  credit.trainCtrl.none,
tuneGrid = data.frame(
k = 7
),
metric = "Accuracy"          # Métrica de evaluación
)
# Evaluación en el conjunto de prueba
predictions <- predict(credit.modelo.final.knn, credit.Datos.knn.Test)
# Calcular matriz de confusión y accuracy
conf_mat <- confusionMatrix(predictions, credit.Datos.knn.Test[[credit.Var.Salida.Usada]])
accuracy <- conf_mat$overall["Accuracy"]
# Mostrar resultados
print(credit.modelo.final.knn)
print(paste("Porcentaje de Acierto (Modelo Final):", round(accuracy * 100, 2), "%"))
credit.Var.Salida.Usada <- c("V16")
credit.Vars.Entrada.Usadas <- setdiff(names(credit.Datos.knn.Train),credit.Var.Salida.Usada)
set.seed(12345)
credit.Datos.Train.knn.downsmpld<-downSample(x=credit.Datos.knn.Train[credit.Vars.Entrada.Usadas],
y=credit.Datos.knn.Train[[credit.Var.Salida.Usada]],
yname=credit.Var.Salida.Usada)
credit.Datos.Test.knn.downsmpld <- credit.Datos.knn.Test
set.seed(1234)
credit.Datos.Train.knn.upsmpld<-upSample(x=credit.Datos.knn.Train[credit.Vars.Entrada.Usadas],
y=credit.Datos.knn.Train[[credit.Var.Salida.Usada]],
yname=credit.Var.Salida.Usada)
credit.Datos.Test.knn.upsmpld<- credit.Datos.knn.Test
set.seed(1234)
credit.modelo.knn.downsmpld <- train(
V16 ~ .,  # Variable de salida ~ Variables de entrada
data = credit.Datos.Train.knn.downsmpld,                                    # Datos de entrenamiento
method = "knn",
trControl =  credit.trainCtrl.none,
tuneGrid = data.frame(
k = 7
),
metric = "Accuracy"
)
#Mostrar porcentaje final
# Realizar predicciones en el conjunto de prueba
predicciones_test <- predict(credit.modelo.knn.downsmpld, credit.Datos.Test.knn.downsmpld)
# Generar la matriz de confusión
matriz_confusion <- confusionMatrix(predicciones_test, credit.Datos.Test.knn.downsmpld[[credit.Var.Salida.Usada]])
# Extraer el porcentaje de acierto
porcentaje_acierto <- matriz_confusion$overall["Accuracy"] * 100
# Mostrar el porcentaje de acierto
print(paste("Porcentaje de acierto:", round(porcentaje_acierto, 2), "%"))
set.seed(1234)
credit.modelo.knn.upsmpld <- train(
V16 ~ .,  # Variable de salida ~ Variables de entrada
data = credit.Datos.Train.knn.upsmpld,                                    # Datos de entrenamiento
method = "knn",
trControl =  credit.trainCtrl.none,
tuneGrid = data.frame(
k = 7
),
metric = "Accuracy"
)
#Mostrar porcentaje final
# Realizar predicciones en el conjunto de prueba
predicciones_test <- predict(credit.modelo.knn.upsmpld, credit.Datos.Test.knn.upsmpld)
# Generar la matriz de confusión
matriz_confusion <- confusionMatrix(predicciones_test, credit.Datos.Test.knn.upsmpld[[credit.Var.Salida.Usada]])
# Extraer el porcentaje de acierto
porcentaje_acierto <- matriz_confusion$overall["Accuracy"] * 100
# Mostrar el porcentaje de acierto
print(paste("Porcentaje de acierto:", round(porcentaje_acierto, 2), "%"))
#Ver importancia de las variables de entrada
#Metodo -> varImp()
varImp(credit.modelo.final.knn)
#Ver seleccion de variables del modelo
#Metodo -> predictors(modelo$finalModel)
predictors(credit.modelo.final.knn)
print(credit.modelo.knn)
modelLookup(("rf"))
varObjetivo <- "V16"
varsPredictoras <- setdiff(names(credit.Datos.Train.imp), varObjetivo)
rf.trainControl.3cv10.twoSummary.roc <- trainControl(
method = "repeatedcv",
number = 10,
repeats = 3,
# No mostramos el proceso porque seria muy extenso
verboseIter = FALSE,
# Métricas adicionales como ROC (para clasificación binaria)
summaryFunction = twoClassSummary,
# Necesario si queremos usar roc
classProbs = TRUE,
# Guardamos todo para hacer diagramas
returnResamp = "all"
)
rf.grid <- expand.grid(mtry = c(1, 2, 4, 6, 10))
# Entrenamiento para 100 arboles
set.seed(123)
rf.modelo.3cv10.twoSummary.roc.100 <- train(
x = credit.Datos.Train.imp[varsPredictoras],
y = credit.Datos.Train.imp[[varObjetivo]],
method = "rf",
metric = "ROC",
trControl = rf.trainControl.3cv10.twoSummary.roc,
tuneGrid = rf.grid,
ntree = 100
)
# Entrenamiento para 500 arboles
set.seed(123)
rf.modelo.3cv10.twoSummary.roc.500 <- train(
x = credit.Datos.Train.imp[varsPredictoras],
y = credit.Datos.Train.imp[[varObjetivo]],
method = "rf",
metric = "ROC",
trControl = rf.trainControl.3cv10.twoSummary.roc,
tuneGrid = rf.grid,
ntree = 500
)
# Entrenamiento para 1000 arboles
set.seed(123)
rf.modelo.3cv10.twoSummary.roc.1000 <- train(
x = credit.Datos.Train.imp[varsPredictoras],
y = credit.Datos.Train.imp[[varObjetivo]],
method = "rf",
metric = "ROC",
trControl = rf.trainControl.3cv10.twoSummary.roc,
tuneGrid = rf.grid,
ntree = 1000
)
maxIndexRf100 <- which.max(rf.modelo.3cv10.twoSummary.roc.100$results$ROC)
# Obtener los valores correspondientes
maxRocRf100 <- rf.modelo.3cv10.twoSummary.roc.100$results$ROC[maxIndexRf100]
mtry100 <- rf.modelo.3cv10.twoSummary.roc.100$results$mtry[maxIndexRf100]
# Imprimir los resultados
cat("El valor más alto de ROC para 100 arboles es:", maxRocRf100, "\n")
cat("Corresponde a mtry:", mtry100, "\n")
maxIndexRf500 <- which.max(rf.modelo.3cv10.twoSummary.roc.500$results$ROC)
# Obtener los valores correspondientes
maxRocRf500 <- rf.modelo.3cv10.twoSummary.roc.500$results$ROC[maxIndexRf500]
mtry500 <- rf.modelo.3cv10.twoSummary.roc.500$results$mtry[maxIndexRf500]
# Imprimir los resultados
cat("El valor más alto de ROC para 500 arboles es:", maxRocRf500, "\n")
cat("Corresponde a mtry:", mtry500, "\n")
maxIndexRf1000 <- which.max(rf.modelo.3cv10.twoSummary.roc.1000$results$ROC)
# Obtener los valores correspondientes
maxRocRf1000 <- rf.modelo.3cv10.twoSummary.roc.1000$results$ROC[maxIndexRf1000]
mtry1000 <- rf.modelo.3cv10.twoSummary.roc.1000$results$mtry[maxIndexRf1000]
# Imprimir los resultados
cat("El valor más alto de ROC para 1000 arboles es:", maxRocRf1000, "\n")
cat("Corresponde a mtry:", mtry1000, "\n")
# Crear un data.frame con los resultados
resultados_df <- data.frame(
mtry = rep(c(1, 2, 4, 6, 10), times = 3), # Repetimos 5 valores de mtry, una vez por modelo
ntree = rep(c(100, 500, 1000), each = 5), # 3 modelos, cada uno con 5 valores de mtry
ROC = c(
rf.modelo.3cv10.twoSummary.roc.100$results$ROC[1:5],
rf.modelo.3cv10.twoSummary.roc.500$results$ROC[1:5],
rf.modelo.3cv10.twoSummary.roc.1000$results$ROC[1:5]
)
)
# Crear el histograma
ggplot(resultados_df, aes(x = as.factor(mtry), y = ROC, fill = as.factor(ntree))) +
geom_bar(stat = "identity", position = "dodge") +
labs(
title = "ROC según Número de mtry y Número de Árboles (imputados NA)",
x = "Número de mtry",
y = "ROC",
fill = "Número de Árboles (ntree)"
) +
scale_fill_manual(values = c("100" = "green", "500" = "purple", "1000" = "red")) +
theme_minimal() +
theme(legend.position = "bottom") +
coord_cartesian(ylim = c(0.9, 1))
# Entrenamiento con valores NA imputados
prediccion.rf.modelo.3cv10.twoSummary.roc.100 <- predict(rf.modelo.3cv10.twoSummary.roc.100, newdata = credit.Datos.Test.imp[varsPredictoras])
prediccion.rf.modelo.3cv10.twoSummary.roc.500 <- predict(rf.modelo.3cv10.twoSummary.roc.500, newdata = credit.Datos.Test.imp[varsPredictoras])
prediccion.rf.modelo.3cv10.twoSummary.roc.1000 <- predict(rf.modelo.3cv10.twoSummary.roc.1000, newdata = credit.Datos.Test.imp[varsPredictoras])
# Generar matriz de confusión
matrizConfusion.rf.modelo.3cv10.twoSummary.roc.100 <- confusionMatrix(
data = prediccion.rf.modelo.3cv10.twoSummary.roc.100,
reference = credit.Datos.Test[[varObjetivo]],
positive = "aprobada" # Cambia esto por la clase objetivo positiva
)
matrizConfusion.rf.modelo.3cv10.twoSummary.roc.500 <- confusionMatrix(
data = prediccion.rf.modelo.3cv10.twoSummary.roc.500,
reference = credit.Datos.Test[[varObjetivo]],
positive = "aprobada" # Cambia esto por la clase objetivo positiva
)
matrizConfusion.rf.modelo.3cv10.twoSummary.roc.1000 <- confusionMatrix(
data = prediccion.rf.modelo.3cv10.twoSummary.roc.1000,
reference = credit.Datos.Test[[varObjetivo]],
positive = "aprobada" # Cambia esto por la clase objetivo positiva
)
# Extraer Accuracy de las matrices de confusión
accuracy_imputados <- c(
matrizConfusion.rf.modelo.3cv10.twoSummary.roc.100$overall["Accuracy"] * 100,
matrizConfusion.rf.modelo.3cv10.twoSummary.roc.500$overall["Accuracy"] * 100,
matrizConfusion.rf.modelo.3cv10.twoSummary.roc.1000$overall["Accuracy"] * 100
)
# Crear un data frame con los resultados
resultados <- data.frame(
Modelo = c("100 Árboles", "500 Árboles", "1000 Árboles"),
Accuracy = accuracy_imputados
)
# Cargar ggplot2
library(ggplot2)
# Crear el histograma
ggplot(resultados, aes(x = Modelo, y = Accuracy, fill = Modelo)) +
geom_bar(stat = "identity", position = "dodge") +
geom_text(aes(label = round(Accuracy, 2)), vjust = -0.5) + # Agregar etiquetas con valores
labs(
title = "Accuracy por Número de Árboles",
x = "Modelo",
y = "Accuracy (%)"
) +
scale_fill_manual(values = c("100 Árboles" = "blue", "500 Árboles" = "green", "1000 Árboles" = "orange")) +
theme_minimal() +
coord_cartesian(ylim = c(80, 100)) +
theme(legend.position = "none")
rf.grid.final.2 <- expand.grid(mtry = c(2))
rf.grid.final.4 <- expand.grid(mtry = c(4))
rf.modelo.3cv10.twoSummary.roc.100.final <- train(
x = credit.Datos.Train.imp[varsPredictoras],
y = credit.Datos.Train.imp[[varObjetivo]],
method = "rf",
metric = "ROC",
trControl = rf.trainControl.3cv10.twoSummary.roc,
tuneGrid = rf.grid.final.2,
ntree = 100
)
rf.modelo.3cv10.twoSummary.roc.500.final <- train(
x = credit.Datos.Train.imp[varsPredictoras],
y = credit.Datos.Train.imp[[varObjetivo]],
method = "rf",
metric = "ROC",
trControl = rf.trainControl.3cv10.twoSummary.roc,
tuneGrid = rf.grid.final.4,
ntree = 500
)
prediccion.rf.modelo.3cv10.twoSummary.roc.100.final <- predict(rf.modelo.3cv10.twoSummary.roc.100.final, newdata = credit.Datos.Test.imp[varsPredictoras])
prediccion.rf.modelo.3cv10.twoSummary.roc.500.final <- predict(rf.modelo.3cv10.twoSummary.roc.500.final, newdata = credit.Datos.Test.imp[varsPredictoras])
matrizConfusion.rf.modelo.3cv10.twoSummary.roc.100.final <- confusionMatrix(
data = prediccion.rf.modelo.3cv10.twoSummary.roc.100.final,
reference = credit.Datos.Test[[varObjetivo]],
positive = "aprobada" # Cambia esto por la clase objetivo positiva
)
matrizConfusion.rf.modelo.3cv10.twoSummary.roc.500.final <- confusionMatrix(
data = prediccion.rf.modelo.3cv10.twoSummary.roc.500.final,
reference = credit.Datos.Test[[varObjetivo]],
positive = "aprobada" # Cambia esto por la clase objetivo positiva
)
# Extraer Accuracy de las matrices de confusión
accuracy_values <- c(
matrizConfusion.rf.modelo.3cv10.twoSummary.roc.100$overall["Accuracy"] * 100,
matrizConfusion.rf.modelo.3cv10.twoSummary.roc.100.final$overall["Accuracy"] * 100,
matrizConfusion.rf.modelo.3cv10.twoSummary.roc.500$overall["Accuracy"] * 100,
matrizConfusion.rf.modelo.3cv10.twoSummary.roc.500.final$overall["Accuracy"] * 100
)
# Crear un data frame con los resultados
resultados <- data.frame(
Modelo = c("100 Árboles", "100 Árboles Final", "500 Árboles", "500 Árboles Final"),
Accuracy = accuracy_values
)
# Cargar ggplot2
library(ggplot2)
# Crear el histograma
ggplot(resultados, aes(x = Modelo, y = Accuracy, fill = Modelo)) +
geom_bar(stat = "identity", position = "dodge") +
geom_text(aes(label = round(Accuracy, 2)), vjust = -0.5) + # Agregar etiquetas con valores
labs(
title = "Accuracy de Modelos Random Forest",
x = "Modelo",
y = "Accuracy (%)"
) +
scale_fill_manual(values = c("100 Árboles" = "blue", "100 Árboles Final" = "lightblue",
"500 Árboles" = "green", "500 Árboles Final" = "lightgreen")) +
theme_minimal() +
coord_cartesian(ylim = c(80, 90)) +
theme(legend.position = "none") # Ocultar leyenda, ya que el eje X describe los modelos
varImp(rf.modelo.3cv10.twoSummary.roc.100)
varImp(rf.modelo.3cv10.twoSummary.roc.100.final)
varImp(rf.modelo.3cv10.twoSummary.roc.500)
varImp(rf.modelo.3cv10.twoSummary.roc.500.final)
print(rf.modelo.3cv10.twoSummary.roc.100.final)
credit.Datos.nnet.Train <- credit.Datos.Train
credit.Datos.nnet.Test <- credit.Datos.Test
credit.Datos.nnet.Train <- credit.Datos.Train.imp
credit.Datos.nnet.Test <- credit.Datos.Test.imp
ejecutar_configuracion("norm_range", "credit.Datos.nnet.Train", "credit.Datos.nnet.Test")
ejecutar_configuracion("norm_center_scale", "credit.Datos.nnet.Train", "credit.Datos.nnet.Test")
ejecutar_configuracion("dummy", "credit.Datos.nnet.Train", "credit.Datos.nnet.Test")
ejecutar_configuracion("var_cero", "credit.Datos.nnet.Train", "credit.Datos.nnet.Test")
modelLookup(("nnet"))
nnet.Grid <- expand.grid(
size = c(1, 2, 3, 4, 7, 10),
decay = c(0.01, 0.1, 0.5, 0.6, 0.7, 1, 2)
)
nnet.trainControl <- trainControl(
method = "repeatedcv",
number = 10,
repeats = 3,
verboseIter = FALSE,
classProbs = TRUE,
summaryFunction = twoClassSummary,
returnResamp = "all"
)
varObjetivo <- "V16"
varsPredictoras <- setdiff(names(credit.Datos.nnet.Train), varObjetivo)
set.seed(123)
nnet.train.100 <- train(
x = credit.Datos.nnet.Train[varsPredictoras],
y = credit.Datos.nnet.Train[[varObjetivo]],
method = "nnet",
metric = "ROC",
trControl = nnet.trainControl,
tuneGrid = nnet.Grid,
trace = FALSE,
maxit = 100
)
set.seed(123)
nnet.train.300 <- train(
x = credit.Datos.nnet.Train[varsPredictoras],
y = credit.Datos.nnet.Train[[varObjetivo]],
method = "nnet",
metric = "ROC",
trControl = nnet.trainControl,
tuneGrid = nnet.Grid,
trace = FALSE,
maxit = 300
)
set.seed(123)
nnet.train.1000 <- train(
x = credit.Datos.nnet.Train[varsPredictoras],
y = credit.Datos.nnet.Train[[varObjetivo]],
method = "nnet",
metric = "ROC",
trControl = nnet.trainControl,
tuneGrid = nnet.Grid,
trace = FALSE,
maxit = 1000
)
# Encontrar el índice del máximo valor de ROC
max_index100 <- which.max(nnet.train.100$results$ROC)
# Obtener los valores correspondientes
max_roc100 <- nnet.train.100$results$ROC[max_index100]
corresponding_size100 <- nnet.train.100$results$size[max_index100]
corresponding_decay100 <- nnet.train.100$results$decay[max_index100]
# Imprimir los resultados
cat("El valor más alto de ROC para 100 iteraciones es:", max_roc100, "\n")
cat("Corresponde a size:", corresponding_size100, "y decay:", corresponding_decay100, "\n")
# Encontrar el índice del máximo valor de ROC
max_index300 <- which.max(nnet.train.300$results$ROC)
# Obtener los valores correspondientes
max_roc300 <- nnet.train.300$results$ROC[max_index300]
corresponding_size300 <- nnet.train.300$results$size[max_index300]
corresponding_decay300 <- nnet.train.300$results$decay[max_index300]
# Imprimir los resultados
cat("El valor más alto de ROC para 300 iteraciones es:", max_roc300, "\n")
cat("Corresponde a size:", corresponding_size300, "y decay:", corresponding_decay300, "\n")
# Encontrar el índice del máximo valor de ROC
max_index1000 <- which.max(nnet.train.1000$results$ROC)
# Obtener los valores correspondientes
max_roc1000 <- nnet.train.1000$results$ROC[max_index1000]
corresponding_size1000 <- nnet.train.1000$results$size[max_index1000]
corresponding_decay1000 <- nnet.train.1000$results$decay[max_index1000]
# Imprimir los resultados
cat("El valor más alto de ROC para 1000 iteraciones es:", max_roc1000, "\n")
cat("Corresponde a size:", corresponding_size1000, "y decay:", corresponding_decay1000, "\n")
prediccion.nnet.100 <- predict(nnet.train.100, newdata = credit.Datos.nnet.Test[varsPredictoras])
prediccion.nnet.300 <- predict(nnet.train.300, newdata = credit.Datos.nnet.Test[varsPredictoras])
prediccion.nnet.1000 <- predict(nnet.train.1000, newdata = credit.Datos.nnet.Test[varsPredictoras])
# Generar matriz de confusión
matrizConfusion.nnet.100 <- confusionMatrix(
data = prediccion.nnet.100,
reference = credit.Datos.Test[[varObjetivo]],
positive = "aprobada" # Cambia esto por la clase objetivo positiva
)
matrizConfusion.nnet.300 <- confusionMatrix(
data = prediccion.nnet.300,
reference = credit.Datos.Test[[varObjetivo]],
positive = "aprobada" # Cambia esto por la clase objetivo positiva
)
matrizConfusion.nnet.1000 <- confusionMatrix(
data = prediccion.nnet.1000,
reference = credit.Datos.Test[[varObjetivo]],
positive = "aprobada" # Cambia esto por la clase objetivo positiva
)
# Extraer Accuracy de las matrices de confusión
accuracy_values <- c(
matrizConfusion.nnet.100$overall["Accuracy"] * 100,
matrizConfusion.nnet.300$overall["Accuracy"] * 100,
matrizConfusion.nnet.1000$overall["Accuracy"] * 100
)
# Crear un data frame con los resultados
resultados <- data.frame(
Modelo = c("100 iteraciones", "300 iteraciones", "1000 iteraciones"),
Accuracy = accuracy_values
)
# Crear el histograma
ggplot(resultados, aes(x = Modelo, y = Accuracy, fill = Modelo)) +
geom_bar(stat = "identity", position = "dodge") +
geom_text(aes(label = round(Accuracy, 2)), vjust = -0.5) + # Agregar etiquetas con valores
labs(
title = "Accuracy de Modelos con Diferentes Iteraciones",
x = "Modelo",
y = "Accuracy (%)"
) +
scale_fill_manual(values = c("100 iteraciones" = "blue", "300 iteraciones" = "green", "500 iteraciones" = "orange")) +
theme_minimal() +
theme(legend.position = "none") +
coord_cartesian(ylim = c(70, 100))
nnet.Grid.final <- expand.grid(
size = c(4),
decay = c(0.5)
)
set.seed(123)
nnet.train.100.final <- train(
x = credit.Datos.nnet.Train[varsPredictoras],
y = credit.Datos.nnet.Train[[varObjetivo]],
method = "nnet",
metric = "ROC",
trControl = nnet.trainControl,
tuneGrid = nnet.Grid.final,
trace = FALSE,
maxit = 100
)
prediccion.nnet.100.final <- predict(nnet.train.100.final, newdata = credit.Datos.nnet.Test[varsPredictoras])
matrizConfusion.nnet.100.final <- confusionMatrix(
data = prediccion.nnet.100.final,
reference = credit.Datos.Test[[varObjetivo]],
positive = "aprobada" # Cambia esto por la clase objetivo positiva
)
# Extraer Accuracy de las matrices de confusión
accuracy_values <- c(
matrizConfusion.nnet.100$overall["Accuracy"] * 100,
matrizConfusion.nnet.100.final$overall["Accuracy"] * 100
)
# Crear un data frame con los resultados
resultados <- data.frame(
Modelo = c("nnet 100 iteraciones", "nnet 100 iteraciones Final"),
Accuracy = accuracy_values
)
# Crear el histograma
ggplot(resultados, aes(x = Modelo, y = Accuracy, fill = Modelo)) +
geom_bar(stat = "identity", position = "dodge") +
geom_text(aes(label = round(Accuracy, 2)), vjust = -0.5) + # Agregar etiquetas con valores
labs(
title = "Accuracy del Modelo nnet (100 iteraciones)",
x = "Modelo",
y = "Accuracy (%)"
) +
scale_fill_manual(values = c("nnet 100 iteraciones" = "blue", "nnet 100 iteraciones Final" = "lightblue")) +
theme_minimal() +
coord_cartesian(ylim = c(80, 90)) +
theme(legend.position = "none") # Ocultar leyenda, ya que el eje X describe los modelos
varImp(nnet.train.100.final)
save.image(file="SesionFinal.RData", compress="xz")
