credit.Var.Salida.Usada <- c("V16")
credit.Vars.Entrada.Usadas <- setdiff(names(credit.Datos.knn.Train),credit.Var.Salida.Usada)
set.seed(12345)
credit.Datos.Train.knn.downsmpld<-downSample(x=credit.Datos.Train.Knn[credit.Vars.Entrada.Usadas],
y=credit.Datos.Train.Knn[[credit.Var.Salida.Usada]],
yname=credit.Var.Salida.Usada)
credit.Datos.svm.Train <- credit.Datos.Train
credit.Datos.svm.Test <- credit.Datos.Test
configuracion_svm <- list(
conf1  = list("dummy"),
conf2  = list("norm_center_scale", "dummy"),
conf3  = list("norm_range", "dummy"),
conf4  = list("dummy", "pca"),
conf5  = list("dummy", "ica"),
conf6  = list("norm_center_scale", "dummy", "pca"),
conf7  = list("norm_center_scale", "dummy", "ica"),
conf8  = list("norm_range", "dummy", "pca"),
conf9  = list("norm_range", "dummy", "ica")
)
ejecutar_configuracion_svm <- function(config, train, test) {
if ("dummy" %in% config) dummy(train, test)
if ("pca" %in% config) pca(train, test)
if ("ica" %in% config) ica(train, test)
if ("norm_range" %in% config) norm_range(train, test)
if ("norm_center_scale" %in% config) norm_center_scale(train, test)
}
modelos_entrenados_svm <- list()
for (i in seq_along(configuracion_svm)) {
# Crear nombre de configuración
nombre_config <- names(configuracion_svm)[i]
preprocesamientos <- configuracion_svm[[i]]
# Restaurar bases de datos originales
credit.Datos.svm.Train <- credit.Datos.Train
credit.Datos.svm.Test <- credit.Datos.Test
# Aplicar configuración
ejecutar_configuracion(preprocesamientos, "credit.Datos.svm.Train", "credit.Datos.svm.Test")
# Quitar variables con varianza cercana a cero
resultados <- eliminar_varianza_cero(credit.Datos.svm.Train, credit.Datos.svm.Test)
# Actualizar los conjuntos de datos
credit.Datos.svm.Train <- resultados$train
credit.Datos.svm.Test <- resultados$test
# Definir variables de entrada y salida
credit.Var.Salida.Usada <- "V16"
credit.Vars.Entrada.Usadas <- setdiff(names(credit.Datos.svm.Train), credit.Var.Salida.Usada)
# Entrenar el modelo
modelo_entrenado <- train(
x = credit.Datos.svm.Train[, credit.Vars.Entrada.Usadas],
y = credit.Datos.svm.Train[[credit.Var.Salida.Usada]],
method = "svmRadial",
trControl = credit.trainCtrl,
tuneGrid = data.frame(
sigma = 0.03951598,
C = 1
),
metric = "Accuracy",
verbose = FALSE
)
# Guardar modelo
modelos_entrenados_svm[[nombre_config]] <- modelo_entrenado
# Mostrar información del modelo actual
print(paste("Modelo entrenado para la configuración:", nombre_config))
}
# Comparar modelos usando resamples()
resultados_resampling <- resamples(modelos_entrenados_svm)
# Mostrar estadísticas resumidas
summary(resultados_resampling)
# Graficar resultados
bwplot(resultados_resampling, metric = "Accuracy")
dotplot(resultados_resampling, metric = "Accuracy")
# Prueba estadística de diferencias
diferencias_modelos <- diff(resultados_resampling)
summary(diferencias_modelos)
credit.Datos.svm.Train <- credit.Datos.Train
credit.Datos.svm.Test <- credit.Datos.Test
dummy("credit.Datos.svm.Train", "credit.Datos.svm.Test")
pca("credit.Datos.svm.Train", "credit.Datos.svm.Test")
# Quitar variables con varianza cercana a cero
resultados <- eliminar_varianza_cero(credit.Datos.svm.Train, credit.Datos.svm.Test)
# Actualizar los conjuntos de datos
credit.Datos.svm.Train <- resultados$train
credit.Datos.svm.Test <- resultados$test
set.seed(1234)
credit.modelo.svm <- train(
V16 ~ .,
data = credit.Datos.svm.Train,                    # Datos de entrenamiento
method = "svmRadial",
trControl = credit.trainCtrl,   # Validación cruzada d
tuneLength = 20                                         # Probar diferentes valores de parámetros
)
#Mostrar porcentaje final
# Realizar predicciones en el conjunto de prueba
predicciones_test <- predict(credit.modelo.svm, credit.Datos.svm.Test)
# Generar la matriz de confusión
matriz_confusion <- confusionMatrix(predicciones_test, credit.Datos.svm.Test[[credit.Var.Salida.Usada]])
# Extraer el porcentaje de acierto
porcentaje_acierto <- matriz_confusion$overall["Accuracy"] * 100
# Mostrar el porcentaje de acierto
print(paste("Porcentaje de acierto:", round(porcentaje_acierto, 2), "%"))
credit.Datos.svm.Train <- credit.Datos.Train
credit.Datos.svm.Test <- credit.Datos.Test
dummy("credit.Datos.svm.Train", "credit.Datos.svm.Test")
nzv.Train <- nearZeroVar(credit.Datos.svm.Train)
nzv.Train
credit.Datos.svm.Train <- credit.Datos.svm.Train[, -nzv.Train]
credit.Datos.svm.Test <- credit.Datos.svm.Test[, names(credit.Datos.svm.Train)]
pca("credit.Datos.svm.Train", "credit.Datos.svm.Test")
# Quitar variables con varianza cercana a cero
#resultados <- eliminar_varianza_cero(credit.Datos.svm.Train, credit.Datos.svm.Test)
# Actualizar los conjuntos de datos
#credit.Datos.svm.Train <- resultados$train
#credit.Datos.svm.Test <- resultados$test
set.seed(1234)
credit.modelo.svm <- train(
V16 ~ .,
data = credit.Datos.svm.Train,                    # Datos de entrenamiento
method = "svmRadial",
trControl = credit.trainCtrl,   # Validación cruzada d
tuneLength = 20                                         # Probar diferentes valores de parámetros
)
#Mostrar porcentaje final
# Realizar predicciones en el conjunto de prueba
predicciones_test <- predict(credit.modelo.svm, credit.Datos.svm.Test)
# Generar la matriz de confusión
matriz_confusion <- confusionMatrix(predicciones_test, credit.Datos.svm.Test[[credit.Var.Salida.Usada]])
# Extraer el porcentaje de acierto
porcentaje_acierto <- matriz_confusion$overall["Accuracy"] * 100
# Mostrar el porcentaje de acierto
print(paste("Porcentaje de acierto:", round(porcentaje_acierto, 2), "%"))
credit.modelo.svm$bestTune
credit.Datos.svm.Train <- credit.Datos.Train
credit.Datos.svm.Test <- credit.Datos.Test
configuracion_svm <- list(
conf1  = list("dummy"),
conf2  = list("norm_center_scale", "dummy"),
conf3  = list("norm_range", "dummy"),
conf4  = list("dummy", "pca"),
conf5  = list("dummy", "ica"),
conf6  = list("norm_center_scale", "dummy", "pca"),
conf7  = list("norm_center_scale", "dummy", "ica"),
conf8  = list("norm_range", "dummy", "pca"),
conf9  = list("norm_range", "dummy", "ica")
)
ejecutar_configuracion_svm <- function(config, train, test) {
if ("dummy" %in% config) dummy(train, test)
if ("pca" %in% config) pca(train, test)
if ("ica" %in% config) ica(train, test)
if ("norm_range" %in% config) norm_range(train, test)
if ("norm_center_scale" %in% config) norm_center_scale(train, test)
}
modelos_entrenados_svm <- list()
for (i in seq_along(configuracion_svm)) {
# Crear nombre de configuración
nombre_config <- names(configuracion_svm)[i]
preprocesamientos <- configuracion_svm[[i]]
# Restaurar bases de datos originales
credit.Datos.svm.Train <- credit.Datos.Train
credit.Datos.svm.Test <- credit.Datos.Test
# Aplicar configuración
ejecutar_configuracion(preprocesamientos, "credit.Datos.svm.Train", "credit.Datos.svm.Test")
# Quitar variables con varianza cercana a cero
resultados <- eliminar_varianza_cero(credit.Datos.svm.Train, credit.Datos.svm.Test)
# Actualizar los conjuntos de datos
credit.Datos.svm.Train <- resultados$train
credit.Datos.svm.Test <- resultados$test
# Definir variables de entrada y salida
credit.Var.Salida.Usada <- "V16"
credit.Vars.Entrada.Usadas <- setdiff(names(credit.Datos.svm.Train), credit.Var.Salida.Usada)
# Entrenar el modelo
modelo_entrenado <- train(
x = credit.Datos.svm.Train[, credit.Vars.Entrada.Usadas],
y = credit.Datos.svm.Train[[credit.Var.Salida.Usada]],
method = "svmRadial",
trControl = trainControl(method = "cv", number = 20),
tuneGrid = data.frame(
sigma = 0.03951598,
C = 1
),
metric = "Accuracy",
verbose = FALSE
)
# Guardar modelo
modelos_entrenados_svm[[nombre_config]] <- modelo_entrenado
# Mostrar información del modelo actual
print(paste("Modelo entrenado para la configuración:", nombre_config))
}
# Comparar modelos usando resamples()
resultados_resampling <- resamples(modelos_entrenados_svm)
# Mostrar estadísticas resumidas
summary(resultados_resampling)
# Graficar resultados
bwplot(resultados_resampling, metric = "Accuracy")
dotplot(resultados_resampling, metric = "Accuracy")
# Prueba estadística de diferencias
diferencias_modelos <- diff(resultados_resampling)
summary(diferencias_modelos)
credit.Datos.svm.Train <- credit.Datos.Train
credit.Datos.svm.Test <- credit.Datos.Test
dummy("credit.Datos.svm.Train", "credit.Datos.svm.Test")
pca("credit.Datos.svm.Train", "credit.Datos.svm.Test")
# Quitar variables con varianza cercana a cero
resultados <- eliminar_varianza_cero(credit.Datos.svm.Train, credit.Datos.svm.Test)
# Actualizar los conjuntos de datos
credit.Datos.svm.Train <- resultados$train
credit.Datos.svm.Test <- resultados$test
set.seed(1234)
credit.modelo.svm <- train(
V16 ~ .,
data = credit.Datos.svm.Train,                    # Datos de entrenamiento
method = "svmRadial",
trControl = trainControl(method = "cv", number = 20),   # Validación cruzada d
tuneLength = 20                                         # Probar diferentes valores de parámetros
)
#Mostrar porcentaje final
# Realizar predicciones en el conjunto de prueba
predicciones_test <- predict(credit.modelo.svm, credit.Datos.svm.Test)
# Generar la matriz de confusión
matriz_confusion <- confusionMatrix(predicciones_test, credit.Datos.svm.Test[[credit.Var.Salida.Usada]])
# Extraer el porcentaje de acierto
porcentaje_acierto <- matriz_confusion$overall["Accuracy"] * 100
# Mostrar el porcentaje de acierto
print(paste("Porcentaje de acierto:", round(porcentaje_acierto, 2), "%"))
credit.Datos.svm.Train <- credit.Datos.Train
credit.Datos.svm.Test <- credit.Datos.Test
norm_center_scale("credit.Datos.svm.Train", "credit.Datos.svm.Test")
dummy("credit.Datos.svm.Train", "credit.Datos.svm.Test")
pca("credit.Datos.svm.Train", "credit.Datos.svm.Test")
# Quitar variables con varianza cercana a cero
resultados <- eliminar_varianza_cero(credit.Datos.svm.Train, credit.Datos.svm.Test)
# Actualizar los conjuntos de datos
credit.Datos.svm.Train <- resultados$train
credit.Datos.svm.Test <- resultados$test
set.seed(1234)
credit.modelo.svm <- train(
V16 ~ .,
data = credit.Datos.svm.Train,                    # Datos de entrenamiento
method = "svmRadial",
trControl = trainControl(method = "cv", number = 20),   # Validación cruzada d
tuneLength = 20                                         # Probar diferentes valores de parámetros
)
#Mostrar porcentaje final
# Realizar predicciones en el conjunto de prueba
predicciones_test <- predict(credit.modelo.svm, credit.Datos.svm.Test)
# Generar la matriz de confusión
matriz_confusion <- confusionMatrix(predicciones_test, credit.Datos.svm.Test[[credit.Var.Salida.Usada]])
# Extraer el porcentaje de acierto
porcentaje_acierto <- matriz_confusion$overall["Accuracy"] * 100
# Mostrar el porcentaje de acierto
print(paste("Porcentaje de acierto:", round(porcentaje_acierto, 2), "%"))
credit.Datos.svm.Train <- credit.Datos.Train
credit.Datos.svm.Test <- credit.Datos.Test
norm_center_scale("credit.Datos.svm.Train", "credit.Datos.svm.Test")
dummy("credit.Datos.svm.Train", "credit.Datos.svm.Test")
#pca("credit.Datos.svm.Train", "credit.Datos.svm.Test")
# Quitar variables con varianza cercana a cero
resultados <- eliminar_varianza_cero(credit.Datos.svm.Train, credit.Datos.svm.Test)
# Actualizar los conjuntos de datos
credit.Datos.svm.Train <- resultados$train
credit.Datos.svm.Test <- resultados$test
set.seed(1234)
credit.modelo.svm <- train(
V16 ~ .,
data = credit.Datos.svm.Train,                    # Datos de entrenamiento
method = "svmRadial",
trControl = trainControl(method = "cv", number = 20),   # Validación cruzada d
tuneLength = 20                                         # Probar diferentes valores de parámetros
)
#Mostrar porcentaje final
# Realizar predicciones en el conjunto de prueba
predicciones_test <- predict(credit.modelo.svm, credit.Datos.svm.Test)
# Generar la matriz de confusión
matriz_confusion <- confusionMatrix(predicciones_test, credit.Datos.svm.Test[[credit.Var.Salida.Usada]])
# Extraer el porcentaje de acierto
porcentaje_acierto <- matriz_confusion$overall["Accuracy"] * 100
# Mostrar el porcentaje de acierto
print(paste("Porcentaje de acierto:", round(porcentaje_acierto, 2), "%"))
credit.Datos.svm.Train <- credit.Datos.Train
credit.Datos.svm.Test <- credit.Datos.Test
#norm_center_scale("credit.Datos.svm.Train", "credit.Datos.svm.Test")
norm_range("credit.Datos.svm.Train", "credit.Datos.svm.Test")
dummy("credit.Datos.svm.Train", "credit.Datos.svm.Test")
#pca("credit.Datos.svm.Train", "credit.Datos.svm.Test")
# Quitar variables con varianza cercana a cero
resultados <- eliminar_varianza_cero(credit.Datos.svm.Train, credit.Datos.svm.Test)
# Actualizar los conjuntos de datos
credit.Datos.svm.Train <- resultados$train
credit.Datos.svm.Test <- resultados$test
set.seed(1234)
credit.modelo.svm <- train(
V16 ~ .,
data = credit.Datos.svm.Train,                    # Datos de entrenamiento
method = "svmRadial",
trControl = trainControl(method = "cv", number = 20),   # Validación cruzada d
tuneLength = 20                                         # Probar diferentes valores de parámetros
)
#Mostrar porcentaje final
# Realizar predicciones en el conjunto de prueba
predicciones_test <- predict(credit.modelo.svm, credit.Datos.svm.Test)
# Generar la matriz de confusión
matriz_confusion <- confusionMatrix(predicciones_test, credit.Datos.svm.Test[[credit.Var.Salida.Usada]])
# Extraer el porcentaje de acierto
porcentaje_acierto <- matriz_confusion$overall["Accuracy"] * 100
# Mostrar el porcentaje de acierto
print(paste("Porcentaje de acierto:", round(porcentaje_acierto, 2), "%"))
credit.Datos.svm.Train <- credit.Datos.Train
credit.Datos.svm.Test <- credit.Datos.Test
#norm_center_scale("credit.Datos.svm.Train", "credit.Datos.svm.Test")
#norm_range("credit.Datos.svm.Train", "credit.Datos.svm.Test")
dummy("credit.Datos.svm.Train", "credit.Datos.svm.Test")
#pca("credit.Datos.svm.Train", "credit.Datos.svm.Test")
# Quitar variables con varianza cercana a cero
resultados <- eliminar_varianza_cero(credit.Datos.svm.Train, credit.Datos.svm.Test)
# Actualizar los conjuntos de datos
credit.Datos.svm.Train <- resultados$train
credit.Datos.svm.Test <- resultados$test
set.seed(1234)
credit.modelo.svm <- train(
V16 ~ .,
data = credit.Datos.svm.Train,                    # Datos de entrenamiento
method = "svmRadial",
trControl = trainControl(method = "cv", number = 20),   # Validación cruzada d
tuneLength = 20                                         # Probar diferentes valores de parámetros
)
#Mostrar porcentaje final
# Realizar predicciones en el conjunto de prueba
predicciones_test <- predict(credit.modelo.svm, credit.Datos.svm.Test)
# Generar la matriz de confusión
matriz_confusion <- confusionMatrix(predicciones_test, credit.Datos.svm.Test[[credit.Var.Salida.Usada]])
# Extraer el porcentaje de acierto
porcentaje_acierto <- matriz_confusion$overall["Accuracy"] * 100
# Mostrar el porcentaje de acierto
print(paste("Porcentaje de acierto:", round(porcentaje_acierto, 2), "%"))
credit.Datos.svm.Train <- credit.Datos.Train
credit.Datos.svm.Test <- credit.Datos.Test
configuracion_svm <- list(
conf1  = list("dummy"),
conf2  = list("norm_center_scale", "dummy"),
conf3  = list("norm_range", "dummy"),
conf4  = list("dummy", "pca"),
conf5  = list("dummy", "ica"),
conf6  = list("norm_center_scale", "dummy", "pca"),
conf7  = list("norm_center_scale", "dummy", "ica"),
conf8  = list("norm_range", "dummy", "pca"),
conf9  = list("norm_range", "dummy", "ica")
)
View(credit.Datos.svm.Train)
View(credit.Datos.svm.Test)
credit.Datos.svm.Train <- credit.Datos.Train
credit.Datos.svm.Test <- credit.Datos.Test
#norm_center_scale("credit.Datos.svm.Train", "credit.Datos.svm.Test")
#norm_range("credit.Datos.svm.Train", "credit.Datos.svm.Test")
dummy("credit.Datos.svm.Train", "credit.Datos.svm.Test")
#pca("credit.Datos.svm.Train", "credit.Datos.svm.Test")
# Quitar variables con varianza cercana a cero
resultados <- eliminar_varianza_cero(credit.Datos.svm.Train, credit.Datos.svm.Test)
# Actualizar los conjuntos de datos
credit.Datos.svm.Train <- resultados$train
credit.Datos.svm.Test <- resultados$test
set.seed(1234)
credit.modelo.svm <- train(
V16 ~ .,
data = credit.Datos.svm.Train,                    # Datos de entrenamiento
method = "svmRadial",
trControl = trainControl(method = "cv", number = 20),   # Validación cruzada d
tuneLength = 20                                         # Probar diferentes valores de parámetros
)
#Mostrar porcentaje final
# Realizar predicciones en el conjunto de prueba
predicciones_test <- predict(credit.modelo.svm, credit.Datos.svm.Test)
# Generar la matriz de confusión
matriz_confusion <- confusionMatrix(predicciones_test, credit.Datos.svm.Test[[credit.Var.Salida.Usada]])
# Extraer el porcentaje de acierto
porcentaje_acierto <- matriz_confusion$overall["Accuracy"] * 100
# Mostrar el porcentaje de acierto
print(paste("Porcentaje de acierto:", round(porcentaje_acierto, 2), "%"))
set.seed(1234)
credit.modelo.svm <- train(
V16 ~ .,
data = credit.Datos.svm.Train,                    # Datos de entrenamiento
method = "svmRadial",
trControl = credit.trainCtrl.3cv10.resampAll,   # Validación cruzada d
tuneLength = 20                                         # Probar diferentes valores de parámetros
)
#Mostrar porcentaje final
# Realizar predicciones en el conjunto de prueba
predicciones_test <- predict(credit.modelo.svm, credit.Datos.svm.Test)
# Generar la matriz de confusión
matriz_confusion <- confusionMatrix(predicciones_test, credit.Datos.svm.Test[[credit.Var.Salida.Usada]])
# Extraer el porcentaje de acierto
porcentaje_acierto <- matriz_confusion$overall["Accuracy"] * 100
# Mostrar el porcentaje de acierto
print(paste("Porcentaje de acierto:", round(porcentaje_acierto, 2), "%"))
credit.Datos.svm.Train <- credit.Datos.Train
credit.Datos.svm.Test <- credit.Datos.Test
#norm_center_scale("credit.Datos.svm.Train", "credit.Datos.svm.Test")
#norm_range("credit.Datos.svm.Train", "credit.Datos.svm.Test")
dummy("credit.Datos.svm.Train", "credit.Datos.svm.Test")
norm_range("credit.Datos.svm.Train", "credit.Datos.svm.Test")
#pca("credit.Datos.svm.Train", "credit.Datos.svm.Test")
# Quitar variables con varianza cercana a cero
resultados <- eliminar_varianza_cero(credit.Datos.svm.Train, credit.Datos.svm.Test)
# Actualizar los conjuntos de datos
credit.Datos.svm.Train <- resultados$train
credit.Datos.svm.Test <- resultados$test
credit.modelo.svm$bestTune
credit.Datos.knn.Train <- credit.Datos.Train
credit.Datos.knn.Test <- credit.Datos.Test
configuracion_knn <- configuracion_svm
ejecutar_configuracion_svm <- function(config, train, test) {
if ("dummy" %in% config) dummy(train, test)
if ("pca" %in% config) pca(train, test)
if ("ica" %in% config) ica(train, test)
if ("norm_range" %in% config) norm_range(train, test)
if ("norm_center_scale" %in% config) norm_center_scale(train, test)
}
modelos_entrenados_knn <- list()
for (i in seq_along(configuracion_knn)) {
# Crear nombre de configuración
nombre_config <- names(configuracion_knn)[i]
preprocesamientos <- configuracion_knn[[i]]
# Restaurar bases de datos originales
credit.Datos.knn.Train <- credit.Datos.Train
credit.Datos.knn.Test <- credit.Datos.Test
# Aplicar configuración
ejecutar_configuracion(preprocesamientos, "credit.Datos.knn.Train", "credit.Datos.knn.Test")
# Quitar variables con varianza cercana a cero
resultados <- eliminar_varianza_cero(credit.Datos.knn.Train, credit.Datos.knn.Test)
# Actualizar los conjuntos de datos
credit.Datos.knn.Train <- resultados$train
credit.Datos.knn.Test <- resultados$test
# Definir variables de entrada y salida
credit.Var.Salida.Usada <- "V16"
credit.Vars.Entrada.Usadas <- setdiff(names(credit.Datos.knn.Train), credit.Var.Salida.Usada)
# Entrenar el modelo
modelo_entrenado <- train(
x = credit.Datos.knn.Train[, credit.Vars.Entrada.Usadas],
y = credit.Datos.knn.Train[[credit.Var.Salida.Usada]],
method = "knn",
trControl = credit.trainCtrl,
tuneGrid = data.frame(
k = 13
),
metric = "Accuracy"
)
# Guardar modelo
modelos_entrenados_knn[[nombre_config]] <- modelo_entrenado
# Mostrar información del modelo actual
print(paste("Modelo entrenado para la configuración:", nombre_config))
}
# Comparar modelos usando resamples()
resultados_resampling <- resamples(modelos_entrenados_knn)
# Mostrar estadísticas resumidas
summary(resultados_resampling)
# Graficar resultados
bwplot(resultados_resampling, metric = "Accuracy")
dotplot(resultados_resampling, metric = "Accuracy")
# Prueba estadística de diferencias
diferencias_modelos <- diff(resultados_resampling)
summary(diferencias_modelos)
credit.Datos.knn.Train <- credit.Datos.Train
credit.Datos.knn.Test <- credit.Datos.Test
norm_range("credit.Datos.knn.Train", "credit.Datos.knn.Test")
dummy("credit.Datos.knn.Train", "credit.Datos.knn.Test")
# Quitar variables con varianza cercana a cero
resultados <- eliminar_varianza_cero(credit.Datos.knn.Train, credit.Datos.knn.Test)
# Actualizar los conjuntos de datos
credit.Datos.knn.Train <- resultados$train
credit.Datos.knn.Test <- resultados$test
# Configurar el modelo KNN
set.seed(1234)
# Entrenamiento del modelo k-NN
credit.modelo.knn <- train(
V16 ~ .,
data = credit.Datos.knn.Train,
method = "knn",  # Especificamos k-NN
trControl = credit.trainCtrl,
tuneLength = 20)
#Mostrar porcentaje final
# Realizar predicciones en el conjunto de prueba
predicciones_test <- predict(credit.modelo.knn, credit.Datos.knn.Test)
# Generar la matriz de confusión
matriz_confusion <- confusionMatrix(predicciones_test, credit.Datos.knn.Test[[credit.Var.Salida.Usada]])
# Extraer el porcentaje de acierto
porcentaje_acierto <- matriz_confusion$overall["Accuracy"] * 100
# Mostrar el porcentaje de acierto
print(paste("Porcentaje de acierto:", round(porcentaje_acierto, 2), "%"))
modelLookup(("knn"))
credit.modelo.knn$bestTune
set.seed(2)
credit.modelo.final.knn <- train(
V16 ~ .,
data = credit.Datos.knn.Train,
method = "knn",
trControl =  credit.trainCtrl.none,
tuneGrid = data.frame(
k = 7
),
metric = "Accuracy"          # Métrica de evaluación
)
# Evaluación en el conjunto de prueba
predictions <- predict(credit.modelo.final.knn, credit.Datos.knn.Test)
# Calcular matriz de confusión y accuracy
conf_mat <- confusionMatrix(predictions, credit.Datos.knn.Test[[credit.Var.Salida.Usada]])
accuracy <- conf_mat$overall["Accuracy"]
# Mostrar resultados
print(credit.modelo.final.knn)
print(paste("Porcentaje de Acierto (Modelo Final):", round(accuracy * 100, 2), "%"))
credit.Var.Salida.Usada <- c("V16")
credit.Vars.Entrada.Usadas <- setdiff(names(credit.Datos.knn.Train),credit.Var.Salida.Usada)
set.seed(12345)
credit.Datos.Train.knn.downsmpld<-downSample(x=credit.Datos.Train.Knn[credit.Vars.Entrada.Usadas],
y=credit.Datos.Train.Knn[[credit.Var.Salida.Usada]],
yname=credit.Var.Salida.Usada)
